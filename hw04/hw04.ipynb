{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OK\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw04.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Functions, Tables, and Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helpful Resource:**\n",
    "- [Python Reference](https://math-121-spring-21.github.io/python-reference.html): Cheat sheet of helpful array & table methods\n",
    "\n",
    "**Reading**: \n",
    "* [Visualizing Numerical Distributions](https://www.inferentialthinking.com/chapters/07/2/Visualizing_Numerical_Distributions.html)\n",
    "* [Functions and Tables](https://www.inferentialthinking.com/chapters/08/Functions_and_Tables.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests. Each time you start your server, you will need to execute this cell again to load the tests.\n",
    "\n",
    "For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space. **Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook!** For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!\n",
    "\n",
    "\n",
    "\n",
    "### **Note: This homework has hidden tests on it. That means even though tests may say 100% passed, doesn't mean your final grade will be 100%. We will be running more tests for correctness once everyone turns in the homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\\n\",\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw04.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing the assignment, execute the submit cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to okpy.org and flag the correct version. There will be another submit cell at the end of the assignment when you finish!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Burrito-ful San Diego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tam, Margaret, and Winifred are trying to use Data Science to find the best burritos in San Diego! Their friends Irene and Maya provided them with two comprehensive datasets on many burrito establishments in the San Diego area taken from (and cleaned from): https://www.kaggle.com/srcole/burritos-in-san-diego/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell reads in a table called `ratings` which contains names of burrito restaurants, their Yelp rating, Google rating, as well as their Overall rating. The Overall rating is not an average of the Yelp and Google ratings, but rather it is the overall rating of the cutomers that were surveyed in the study above.\n",
    "\n",
    "\n",
    "It also reads in a table called `burritos_types` which contains names of burrito restaurants, their menu items, and the cost of the respective menu item at the restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this cell\n",
    "ratings = Table.read_table(\"ratings.csv\")\n",
    "ratings.show(5)\n",
    "burritos_types = Table.read_table(\"burritos_types.csv\")\n",
    "burritos_types.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** It would be easier if we could combine the information in both tables. Assign `burritos` to the result of joining the two tables together, so that we have a table with the ratings for every corresponding menu item from every restaurant. Each menu item has the same rating as the restaurant from which it is from.\n",
    "\n",
    "*Note: it doesn't matter which table you put in as the argument to the table method, either order will work for the autograder tests.*\n",
    "\n",
    "*Hint: If you need help on using the join method, look at the [python reference](https://math-121-spring-21.github.io/python-reference.html) or [Section 8.4](https://www.inferentialthinking.com/chapters/08/4/Joining_Tables_by_Columns.html) in the textbook.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "burritos = ...\n",
    "burritos.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Let's look at how the Yelp scores compare to the Google scores in the `burritos` table. First, assign `yelp_and_google` to a table only containing the columns `Yelp` and `Google`. Then, make a scatter plot with Yelp scores on the x-axis and the Google scores on the y-axis. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_2\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "yelp_and_google = ...\n",
    "...\n",
    "# Don't change/edit/remove the following line.\n",
    "# To help you make conclusions, we have plotted a straight line on the graph (y=x)\n",
    "plt.plot(np.arange(2.5,5,.5), np.arange(2.5,5,.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Looking at the scatter plot you just made in Question 1.2, do you notice any pattern(s) (i.e. is one of the two types of scores consistently higher than the other one)? If so, describe them **briefly** in the cell below.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_3\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start the next question, refresh yourself on how `.group` works. You can read how `.group` in the [textbook](https://www.inferentialthinking.com/chapters/08/2/Classifying_by_One_Variable.html), or you can view the video below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"HLoYTCUP0fc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** There are so many types of California burritos in the `burritos` table! Winifred wants to know which type is the highest rated across all restaurants.\n",
    "\n",
    "Create a table that has two columns: the name of the burrito and the average overall rating of that burrito across restuarants. **In your calculations, you should compare burritos that contain the word \"California\".** For example, there's \"California\" burritos, \"California breakfast\" burritos, \"California Surf and Turf\" burritos, etc.\n",
    "\n",
    "*Tip: If multiple restaurants serve the \"California - Chicken\" burrito, what table method can we use to aggregate those together and find the average overall rating?* \n",
    "\n",
    "*Note: you can break up the solution into multiple lines, as long as you assign the final output table to `california_burritos`! For reference however, the solution key only used one line.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "california_burritos = ...\n",
    "california_burritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_4\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Given this new table `california_burritos`, Winifred can figure out the name of the California burrito with the highest overall average rating! Assign `best_california_burrito` to a line of code that evaluates to a string that corresponds to the name of the California burrito with the highest overall average rating. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_california_burrito = ...\n",
    "best_california_burrito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Using the `burritos` table, assign `menu_average` to a table that has three columns that uniquely pairs the name of the restaurant, the menu item featured in the review, and the average Overall score for that menu item at that restaurant.\n",
    "\n",
    "*Hint: Use .group, and remember that you can group by multiple columns. Here's an example from the [textbook](https://www.inferentialthinking.com/chapters/08/3/Cross-Classifying_by_More_than_One_Variable.html)*.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_average = ...\n",
    "menu_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_6\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Tam thinks that burritos in San Diego are cheaper (and taste better) than the burritos in Berkeley. Plot a histogram that visualizes that distribution of the costs of the burritos from San Diego in the `burritos` table. Also use the provided `bins` variable when making your histogram, so that visually the histogram is more informative.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_7\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "bins = np.arange(0, 15, 1)\n",
    "# Please also use the provided bins\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** What percentage of burritos in San Diego are less than $6? Assign `burritos_less_than_6` to your answer, which should be between 0 and 100. You should only use the histogram above to answer the question. Do not use code to find the answer, just eyeball the heights and use arithmetic!\n",
    "\n",
    "Your answer does not have to be exact, but it should be within 3 or 4 of the correct answer. I.e., if the correct answer was 87\\%, anything from 83-91 would be ok.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_8\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "burritos_less_than_6 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q1_8\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NBA Salaries (again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is designed to give you practice using the Table methods `pivot` and `group`. [Here](https://math-121-spring-21.github.io/python-reference.html) is a link to the Python reference page in case you need a quick refresher.\n",
    "\n",
    "Run the cell below to view a demo on how you can use pivot on a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"4WzXo8eKLAg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we load a dataset containing the salary info for all the players in the NBA by team and position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = Table.read_table(\"nba_salaries_2021.csv\")\n",
    "nba.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use this table to generate arrays with the names of each player on each team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Set `player_names` to a table with two columns. The first column should be called `Team` and have the name of every team once, and the second column should be called `Players` with each row in that second column containing an *array* of the names of all players on that team. \n",
    "\n",
    "*Hint:* Think about how ```group``` works: it collects values into an array and then applies a function to that array. We have defined two functions below for you, and you will need to use one of them in your call to ```group```.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one of the two functions defined below in your call to group.\n",
    "def function1(array):\n",
    "    '''Returns the first item'''\n",
    "    return array.item(0)\n",
    "\n",
    "def function2(array):\n",
    "    '''Returns the array that is passed through'''\n",
    "    return array \n",
    "\n",
    "# Make a call to group using one of the functions above when you define player_names\n",
    "player_names = ...\n",
    "player_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the code you just wrote in 2.1 is important for moving forward with the class! If you made a lucky guess, take some time to look at the code, step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** At the moment, the ```Player``` column of the `nba` table is sorted by team name, and first name. Would the arrays you generated in the `Players` column of the previous part be the same if we had sorted by the position column instead before generating them? Two arrays are the **same** if they contain the same number of elements and the elements located at corresponding indexes in the two arrays are identical. An example of arrays that are NOT the same: `array([1,2]) != array([2,1])`. Explain your answer.  \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_2\n",
    "manual: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true,
    "manual_problem_id": "faculty_1"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Set `team_position_ranges` to a table containing the teams as the rows, and the position as the columns. The values in the rows should correspond to a salary range, where range is defined as the **difference between the highest salary and the lowest salary on the team for that position**. \n",
    "\n",
    "*Hint 1: First you'll need to define a new function `salary_range` which takes in an array of salaries and returns the range of salaries in that array.*\n",
    "\n",
    "*Hint 2: What table function allows you to specify the rows and columns of a new table? You probably watched a video on it earlier in the homework!*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_3\n",
    "manual: false\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define salary_range first\n",
    "...\n",
    "    ...\n",
    "\n",
    "team_position_ranges = ...\n",
    "team_position_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_3\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Give an explanation as to why some of the row values are `0` in the `team_position_ranges` table from the previous question.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_4\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "export_pdf": true
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Create a new table called `teams_and_counts` with a column for `Team` and a column called `count` for the number of positions (i.e., PG, SG, SF, PF, or C) on that team with an average salary above $15,000,000. If the team doesn’t have any position groups with an average salary above 15 million, then it should not have a row in the final table.\n",
    "\n",
    "*Hint 1: Use pen and paper to draw out the intermediate tables to answer this question. This question is difficult! The variable names provided are meant to help guide the intermediate steps and general thought process.*\n",
    "\n",
    "*Hint 2: Remember that you can group by multiple columns. Here's an example from the [textbook](https://www.inferentialthinking.com/chapters/08/3/Cross-Classifying_by_More_than_One_Variable.html).*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_5\n",
    "manual: True\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "without_names = ...\n",
    "salaries_by_position = ...\n",
    "positions_above_15m = ...\n",
    "teams_and_counts = ...\n",
    "teams_and_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.grade(\"q2_5\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once you're finished, select \"Save and Checkpoint\" in the File menu and then execute the `submit` cell below. The result will contain a link that you can use to check that your assignment has been submitted successfully. If you submit more than once before the deadline, we will only grade your final submission. If you mistakenly submit the wrong one, you can head to [okpy.org](https://okpy.org/) and flag the correct version. To do so, go to the website, click on this assignment, and find the version you would like to have graded. There should be an option to flag that submission for grading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q') and len(q) <= 10]\n",
    "print(\"Finished running all tests.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
